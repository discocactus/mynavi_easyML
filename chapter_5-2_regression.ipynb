{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:53:58.126504Z",
     "start_time": "2018-04-21T10:53:57.266398Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:00.407357Z",
     "start_time": "2018-04-21T10:54:00.376759Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習データを読み込む\n",
    "# x: 広告費用\n",
    "# y: クリック数\n",
    "train = np.loadtxt('click.csv', delimiter=',', skiprows=1)\n",
    "train_x = train[:,0]\n",
    "train_y = train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:02.470076Z",
     "start_time": "2018-04-21T10:54:02.267587Z"
    }
   },
   "outputs": [],
   "source": [
    "# プロット\n",
    "plt.plot(train_x, train_y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__標準化(z-score正規化)__  \n",
    "平均を0、分散を1に変換(標準偏差に対してどのくらいの値か)  \n",
    "パラメーターの収束が早くなる  \n",
    "__$\\mu$ (mu) = 平均__  \n",
    "__$\\sigma$ (sigma) = 分散__    \n",
    "$$\n",
    "\\begin{align}\n",
    "{z^{(i)}} = \\frac{x^{(i)}-\\mu}{\\sigma}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:06.707775Z",
     "start_time": "2018-04-21T10:54:06.692143Z"
    }
   },
   "outputs": [],
   "source": [
    "# 標準化(z-score正規化)\n",
    "mu = train_x.mean()\n",
    "sigma = train_x.std()\n",
    "def standardize(x):\n",
    "    return (x - mu) / sigma\n",
    "\n",
    "train_z = standardize(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:07.911273Z",
     "start_time": "2018-04-21T10:54:07.802013Z"
    }
   },
   "outputs": [],
   "source": [
    "# 標準化後プロット\n",
    "plt.plot(train_z, train_y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次関数として実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__予測関数__  \n",
    "切片と傾き  \n",
    "$$\n",
    "\\begin{align}\n",
    "f_\\theta = \\theta_0 + \\theta_1x\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:13.200246Z",
     "start_time": "2018-04-21T10:54:13.169599Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測関数\n",
    "def f(x):\n",
    "    return theta0 + theta1 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__目的関数__  \n",
    "学習データと予測値の誤差の二乗の総和  \n",
    "$E(\\theta)$ が最小となる $\\theta$ を求めたい  \n",
    "$\\frac{1}{2}$ は学習に用いる式を導出する際に微分計算で出てくる 2 を相殺するために付けられた定数なので、  \n",
    "なくても最終的な結果は変わらないが、この定数の大小は収束までの計算回数に若干影響する  \n",
    "$$\n",
    "\\begin{align}\n",
    "E(\\theta) = \\frac{1}{2} \\sum_{i=1}^{n} \\left( y^{(i)} - f_\\theta (x^{(i)}) \\right) ^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:15.403605Z",
     "start_time": "2018-04-21T10:54:15.387926Z"
    }
   },
   "outputs": [],
   "source": [
    "# 目的関数\n",
    "def E(x, y):\n",
    "    return 0.5 * np.sum((y - f(x)) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__パラメーターの更新式の導出__  \n",
    "__最急降下法、勾配降下法__  \n",
    "導関数の符号と逆方向に $\\theta$ をずらして(減算)行けば最小値の方に向かう  \n",
    "$f_\\theta(x)$ は $\\theta_0$ と $\\theta_1$ を持つ2変数関数なので偏微分を行う  \n",
    "__$\\eta$ (eta) = 学習率__  \n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\theta_0 := \\theta_0 - \\eta \\frac{\\partial E}{\\partial \\theta_0} \\\\\n",
    "& \\theta_1 := \\theta_1 - \\eta \\frac{\\partial E}{\\partial \\theta_1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで $\\theta_0$, $\\theta_1$ はそれぞれ $E(\\theta)$ の中の $f_\\theta(x)$ の中にあるので、、、  \n",
    "$$\n",
    "\\begin{align*}\n",
    "& u = E(\\theta) = \\frac{1}{2} \\sum_{i=1}^{n} \\left( y^{(i)} - f_\\theta (x^{(i)}) \\right) ^2\\\\\n",
    "& v = f_\\theta(x) = \\theta_0 + \\theta_1x\n",
    "\\end{align*}\n",
    "$$\n",
    "として、合成関数の微分を行う    \n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\frac{\\partial u}{\\partial \\theta_0} = \\frac{\\partial u}{\\partial v}\\cdot\\frac{\\partial v}{\\partial \\theta_0} \\\\\n",
    "& \\frac{\\partial u}{\\partial \\theta_1} = \\frac{\\partial u}{\\partial v}\\cdot\\frac{\\partial v}{\\partial \\theta_1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__$\\theta_0$ の更新式の導出__  \n",
    "・$u$ を $v$ で微分  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial u}{\\partial v} & = \\frac{\\partial}{\\partial v} \\left( \\frac{1}{2} \\sum_{i=1}^{n} \\left( y^{(i)} - v \\right) ^2 \\right) \\\\\n",
    "& = \\frac{1}{2} \\sum_{i=1}^{n} \\left( \\frac{\\partial}{\\partial v} \\left( y^{(i)} - v \\right) ^2 \\right) \\\\\n",
    "& = \\frac{1}{2} \\sum_{i=1}^{n} \\left( \\frac{\\partial}{\\partial v} \\left( y^{(i)^2} - 2y^{(i)}v +v^2 \\right) \\right) \\\\\n",
    "& = \\frac{1}{2} \\sum_{i=1}^{n} \\left( -2y^{(i)} + 2v \\right) \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( v -y^{(i)} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "・$v$ を $\\theta_0$ で微分  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial v}{\\partial \\theta_0} & = \\frac{\\partial}{\\partial \\theta_0} (\\theta_0 + \\theta_1 x) \\\\\n",
    "& = 1\n",
    "\\end{align*}\n",
    "$$\n",
    "・それぞれの結果を掛けて、$v$ を $f_\\theta(x)$ に戻す  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial u}{\\partial \\theta_0} & = \\frac{\\partial u}{\\partial v}\\cdot\\frac{\\partial v}{\\partial \\theta_0} \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( v -y^{(i)} \\right) \\cdot 1 \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) -y^{(i)} \\right)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__$\\theta_1$ の更新式の導出__  \n",
    "・$u$ を $v$ で微分する部分は $\\theta_0$ について求めたものと同じ  \n",
    "・$v$ を $\\theta_1$ で微分  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial v}{\\partial \\theta_1} & = \\frac{\\partial}{\\partial \\theta_1} (\\theta_0 + \\theta_1 x) \\\\\n",
    "& = x\n",
    "\\end{align*}\n",
    "$$\n",
    "・それぞれの結果を掛けて、$v$ を $f_\\theta(x)$ に戻す  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial u}{\\partial \\theta_1} & = \\frac{\\partial u}{\\partial v}\\cdot\\frac{\\partial v}{\\partial \\theta_1} \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( v -y^{(i)} \\right) \\cdot x^{(i)} \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) -y^{(i)} \\right) \\cdot x^{(i)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__パラメーターの更新式__  \n",
    "1つ前の $\\theta_0$ - 学習率 \\* 目的関数を $\\theta_0$ で偏微分して求めた導関数の総和  \n",
    "1つ前の $\\theta_1$ - 学習率 \\* 目的関数を $\\theta_1$ で偏微分して求めた導関数の総和  \n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\theta_0 := \\theta_0 - \\eta \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) - y^{(i)} \\right) \\\\\n",
    "& \\theta_1 := \\theta_1 - \\eta \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:21.232355Z",
     "start_time": "2018-04-21T10:54:21.169791Z"
    }
   },
   "outputs": [],
   "source": [
    "# パラメーターを初期化\n",
    "# 0〜1の一様乱数\n",
    "theta0 = np.random.rand()\n",
    "theta1 = np.random.rand()\n",
    "\n",
    "# 学習率\n",
    "ETA = 1e-3\n",
    "\n",
    "# 誤差の差分\n",
    "diff = 1\n",
    "\n",
    "# 更新回数\n",
    "count = 0\n",
    "\n",
    "# 誤差の初期値\n",
    "error = E(train_z, train_y)\n",
    "\n",
    "# 誤差の差分が計算打ち切り値0.01以下になるまでパラメータ更新を繰り返す\n",
    "while diff > 1e-2:\n",
    "    # 各パラメーターの更新は同時に行わなければいけないので、更新結果を一時変数に保存\n",
    "    # 下の順番で計算する場合だと、theta1の計算時には直前に計算したtheta0ではなく、1つ前のtheta0を使う\n",
    "    # 1つ前のtheta0 - 学習率 * 目的関数をtheta0で偏微分した結果(合成関数を使って求める)の総和\n",
    "    tmp0 = theta0 - ETA * np.sum((f(train_z) - train_y))\n",
    "    # 1つ前のtheta1 - 学習率 * 目的関数をtheta1で偏微分した結果(合成関数を使って求める)の総和\n",
    "    tmp1 = theta1 - ETA * np.sum((f(train_z) - train_y) * train_z)\n",
    "    # パラメータを更新\n",
    "    theta0 = tmp0\n",
    "    theta1 = tmp1\n",
    "    # 前回の誤差との差分を計算\n",
    "    current_error = E(train_z, train_y)\n",
    "    diff = error - current_error\n",
    "    error = current_error\n",
    "    # ログの出力\n",
    "    count += 1\n",
    "    log = '{}回目: theta0 = {:.3f}, theta1 = {:.3f}, 差分 = {:.4f}'\n",
    "    print(log.format(count, theta0, theta1, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:25.748404Z",
     "start_time": "2018-04-21T10:54:25.639675Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 結果をプロット\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(train_z, train_y, 'o')\n",
    "plt.plot(x, f(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多項式回帰の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__多項式回帰の予測関数__  \n",
    "$$\n",
    "\\begin{align}\n",
    "f_\\theta(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータと変数をそれぞれベクトルとみなすことで計算式を簡単にする  \n",
    "  \n",
    "$$\n",
    "\\boldsymbol{\\theta} = \\left[\n",
    "\\begin{array}{c}\n",
    "  \\theta_0 \\\\\n",
    "  \\theta_1 \\\\\n",
    "  \\theta_2\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\qquad\n",
    "\\boldsymbol{x(i)} = \\left[\n",
    "\\begin{array}{c}\n",
    "  1 \\\\\n",
    "  x^{(i)} \\\\\n",
    "  x^{(i)^2}\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データが複数あるので1行を1つの学習データとみなして行列として考える  \n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \\left[\n",
    "\\begin{array}{c}\n",
    "  \\boldsymbol{x}^{(1)^T} \\\\\n",
    "  \\boldsymbol{x}^{(2)^T} \\\\\n",
    "  \\boldsymbol{x}^{(3)^T} \\\\\n",
    "  \\vdots \\\\\n",
    "  \\boldsymbol{x}^{(n)^T}\n",
    "\\end{array}\n",
    "\\right]\n",
    "= \\left[\n",
    "\\begin{array}{ccc}\n",
    "  1 & x^{(1)} & x^{(1)^2} \\\\\n",
    "  1 & x^{(2)} & x^{(2)^2} \\\\\n",
    "  1 & x^{(3)} & x^{(3)^2} \\\\\n",
    "  & \\vdots & \\\\\n",
    "  1 & x^{(n)} & x^{(n)^2}\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:31.920937Z",
     "start_time": "2018-04-21T10:54:31.890352Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習データの行列を作る関数\n",
    "def to_matrix(x):\n",
    "    # theta0に対応するx0を1とした行列を転置\n",
    "    return np.vstack([np.ones(x.shape[0]), x, x ** 2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:33.811762Z",
     "start_time": "2018-04-21T10:54:33.796136Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習データの行列を作る\n",
    "X = to_matrix(train_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:36.740951Z",
     "start_time": "2018-04-21T10:54:36.710317Z"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データの行列 $\\boldsymbol{X}$ とパラメータのベクトル $\\boldsymbol{\\theta}$ の積をとる\n",
    "\n",
    "$$\n",
    "f_\\boldsymbol{\\theta}(\\boldsymbol{x}^{(i)}) = \\boldsymbol{X\\theta} = \\left[\n",
    "\\begin{array}{ccc}\n",
    "  1 & x^{(1)} & x^{(1)^2} \\\\\n",
    "  1 & x^{(2)} & x^{(2)^2} \\\\\n",
    "  1 & x^{(3)} & x^{(3)^2} \\\\\n",
    "  & \\vdots & \\\\\n",
    "  1 & x^{(n)} & x^{(n)^2}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "  \\theta_0 \\\\\n",
    "  \\theta_1 \\\\\n",
    "  \\theta_2\n",
    "\\end{array}\n",
    "\\right] = \\left[\n",
    "\\begin{array}{c}\n",
    "  \\theta_0 + \\theta_1 x^{(1)} + \\theta_2 x^{(1)^2} \\\\\n",
    "  \\theta_0 + \\theta_1 x^{(2)} + \\theta_2 x^{(2)^2} \\\\\n",
    "  \\vdots \\\\\n",
    "  \\theta_0 + \\theta_1 x^{(n)} + \\theta_2 x^{(n)^2}\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:44.147990Z",
     "start_time": "2018-04-21T10:54:44.132374Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測関数\n",
    "def f(x):\n",
    "    # 学習データの行列xとパラメータのベクトルthetaの積を求める\n",
    "    return np.dot(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T11:10:43.895914Z",
     "start_time": "2018-04-21T11:10:43.880313Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参考\n",
    "f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T11:01:20.538392Z",
     "start_time": "2018-04-21T11:01:20.523203Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参考\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T11:07:26.609290Z",
     "start_time": "2018-04-21T11:07:26.593696Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参考\n",
    "# f(X)[0] =\n",
    "theta[0] + theta[1] * X[0][1] + theta[2] * X[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__追加された $\\theta_2$ の更新式の導出__  \n",
    "・$u$ を $v$ で微分する部分は $\\theta_0$ について求めたものと同じ  \n",
    "・$v$ を $\\theta_2$ で微分  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial v}{\\partial \\theta_2} & = \\frac{\\partial}{\\partial \\theta_2} (\\theta_0 + \\theta_1 x +\\theta_2 x^2) \\\\\n",
    "& = x^2\n",
    "\\end{align*}\n",
    "$$\n",
    "・それぞれの結果を掛けて、$v$ を $f_\\theta(x)$ に戻す  \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial u}{\\partial \\theta_2} & = \\frac{\\partial u}{\\partial v}\\cdot\\frac{\\partial v}{\\partial \\theta_2} \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( v -y^{(i)} \\right) \\cdot x^{(i)^2} \\\\\n",
    "& = \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) -y^{(i)} \\right) \\cdot x^{(i)^2}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__パラメーターの更新式__  \n",
    "1つ前の $\\theta_0$ - 学習率 \\* 目的関数を $\\theta_0$ で偏微分して求めた導関数の総和  \n",
    "1つ前の $\\theta_1$ - 学習率 \\* 目的関数を $\\theta_1$ で偏微分して求めた導関数の総和  \n",
    "1つ前の $\\theta_2$ - 学習率 \\* 目的関数を $\\theta_2$ で偏微分して求めた導関数の総和  \n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\theta_0 := \\theta_0 - \\eta \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) - y^{(i)} \\right) \\\\\n",
    "& \\theta_1 := \\theta_1 - \\eta \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)} \\\\\n",
    "& \\theta_2 := \\theta_2 - \\eta \\sum_{i=1}^{n} \\left( f_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)^2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "__パラメーターの数を $j$ として一般化__  \n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\theta_j := \\theta_j - \\eta \\sum_{i=1}^{n} \\left( f_\\boldsymbol{\\theta}(\\boldsymbol{x}^{(i)}) - y^{(i)} \\right) x_j^{(i)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで $j$=0 の時、$f_\\theta(\\boldsymbol{x}^{(i)}) - y^{(i)}$ と $x_0^{(i)}$ をそれぞれベクトルとして考える\n",
    "$$\n",
    "\\boldsymbol{f} = \\left[\n",
    "\\begin{array}{c}\n",
    "  f_\\theta(\\boldsymbol{x}^{(1)}) - y^{(1)} \\\\\n",
    "  f_\\theta(\\boldsymbol{x}^{(2)}) - y^{(2)} \\\\\n",
    "  \\vdots \\\\\n",
    "  f_\\theta(\\boldsymbol{x}^{(n)}) - y^{(n)}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\qquad\n",
    "\\boldsymbol{x_0} = \\left[\n",
    "\\begin{array}{c}\n",
    "  x_0^{(1)} \\\\\n",
    "  x_0^{(2)} \\\\\n",
    "  \\vdots \\\\\n",
    "  x_0^{(n)}\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "この $\\boldsymbol{f}$ を転置して $\\boldsymbol{x_0}$ と掛け合わせれば更新式の総和の部分と同じになる  \n",
    "\n",
    "同様にして $\\boldsymbol{f}^{\\mathrm{T}}$ と $x_j^{(i)}$ の行列 $\\boldsymbol{X}$ を掛け合わせたものを更新式に用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:52.992684Z",
     "start_time": "2018-04-21T10:54:52.836415Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# パラメータを初期化\n",
    "theta = np.random.rand(3)\n",
    "\n",
    "# 誤差の差分\n",
    "diff = 1\n",
    "\n",
    "# 更新回数\n",
    "count = 0\n",
    "\n",
    "# 学習を繰り返す\n",
    "error = E(X, train_y)\n",
    "while diff > 1e-2:\n",
    "    # パラメータを更新\n",
    "    # パラメータのベクトル - 学習率 * 誤差ベクトルと学習データ行列の積\n",
    "    theta = theta - ETA * np.dot(f(X) - train_y, X)\n",
    "    # 前回の誤差との差分を計算\n",
    "    current_error = E(X, train_y)\n",
    "    diff = error - current_error\n",
    "    error = current_error\n",
    "    # ログの出力\n",
    "    count += 1\n",
    "    log = '{}回目: theta = {}, 差分 = {:.4f}'\n",
    "    print(log.format(count, theta, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T10:54:58.743356Z",
     "start_time": "2018-04-21T10:54:58.633933Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果をプロット\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(train_z, train_y, 'o')\n",
    "plt.plot(x, f(to_matrix(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T06:27:59.666719Z",
     "start_time": "2018-04-08T06:27:59.635732Z"
    }
   },
   "outputs": [],
   "source": [
    "# 平均二乗誤差\n",
    "def MSE(x, y):\n",
    "    return (1 / x.shape[0]) * np.sum((y - f(x)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T08:40:17.642115Z",
     "start_time": "2018-04-08T08:40:17.470238Z"
    }
   },
   "outputs": [],
   "source": [
    "# 目的関数(計算打ち切りの条件)を平均二乗誤差で計算\n",
    "\n",
    "# パラメータを初期化\n",
    "theta = np.random.rand(3)\n",
    "\n",
    "# 平均二乗誤差の履歴\n",
    "errors = []\n",
    "\n",
    "# 誤差の差分\n",
    "diff = 1\n",
    "\n",
    "# 更新回数\n",
    "count = 0\n",
    "\n",
    "# 学習を繰り返す\n",
    "errors.append(MSE(X, train_y))\n",
    "while diff > 1e-2:\n",
    "    # パラメータを更新\n",
    "    theta = theta - ETA * np.dot(f(X) - train_y, X)\n",
    "    # 前回の誤差との差分を計算\n",
    "    errors.append(MSE(X, train_y))\n",
    "    diff = errors[-2] - errors[-1]\n",
    "    # ログの出力\n",
    "    count += 1\n",
    "    log = '{}回目: theta = {}, 差分 = {:.4f}'\n",
    "    print(log.format(count, theta, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T06:38:17.797414Z",
     "start_time": "2018-04-08T06:38:17.688444Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果をプロット\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(train_z, train_y, 'o')\n",
    "plt.plot(x, f(to_matrix(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T06:39:33.699816Z",
     "start_time": "2018-04-08T06:39:33.590838Z"
    }
   },
   "outputs": [],
   "source": [
    "# 誤差をプロット\n",
    "x = np.arange(len(errors))\n",
    "\n",
    "plt.plot(x, errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率的勾配降下法の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T06:49:59.560660Z",
     "start_time": "2018-04-08T06:49:59.326221Z"
    }
   },
   "outputs": [],
   "source": [
    "# パラメータを初期化\n",
    "theta = np.random.rand(3)\n",
    "\n",
    "# 平均二乗誤差の履歴\n",
    "errors = []\n",
    "\n",
    "# 誤差の差分\n",
    "diff = 1\n",
    "\n",
    "# 更新回数\n",
    "count = 0\n",
    "\n",
    "# 学習を繰り返す\n",
    "errors.append(MSE(X, train_y))\n",
    "while diff > 1e-2:\n",
    "    # 学習データを並べ替えるためにランダムな順列を用意する\n",
    "    p = np.random.permutation(X.shape[0])\n",
    "    #　学習データをランダムに取り出して確率的勾配降下法でパラメータ更新\n",
    "    for x, y in zip(X[p,:], train_y[p]):\n",
    "        theta = theta - ETA * (f(x) - y) * x\n",
    "    # 前回の誤差との差分を計算\n",
    "    errors.append(MSE(X, train_y))\n",
    "    diff = errors[-2] - errors[-1]\n",
    "    # ログの出力\n",
    "    count += 1\n",
    "    log = '{}回目: theta = {}, 差分 = {:.4f}'\n",
    "    print(log.format(count, theta, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T06:50:49.881920Z",
     "start_time": "2018-04-08T06:50:49.756867Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果をプロット\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(train_z, train_y, 'o')\n",
    "plt.plot(x, f(to_matrix(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T06:51:07.039972Z",
     "start_time": "2018-04-08T06:51:06.914923Z"
    }
   },
   "outputs": [],
   "source": [
    "# 誤差をプロット\n",
    "x = np.arange(len(errors))\n",
    "\n",
    "plt.plot(x, errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
